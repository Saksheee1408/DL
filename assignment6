import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np

# 1ï¸âƒ£ Load IMDB dataset (only top 10,000 words)
(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)

# 2ï¸âƒ£ Pad all sequences to same length (LSTMs need equal-sized inputs)
x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=200)
x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=200)

# 3ï¸âƒ£ Build LSTM model
model = keras.Sequential([
    layers.Embedding(10000, 64),
    layers.LSTM(64),
    layers.Dense(1, activation='sigmoid')
])

# 4ï¸âƒ£ Compile and train
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs=3, batch_size=64,
                    validation_data=(x_test, y_test), verbose=1)

# 5ï¸âƒ£ Plot accuracy
plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='test')
plt.legend()
plt.title("LSTM Accuracy")
plt.show()

# 6ï¸âƒ£ Test 5 random samples from test set
for i in [0, 1, 2, 3, 4]:
    pred = model.predict(x_test[i:i+1])[0][0]
    print(f"Sample {i} â†’", "Positive ğŸ˜Š" if pred > 0.5 else "Negative ğŸ˜", "| Score:", round(pred, 3))
